{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件数19320\n",
      "文件夹大小112.25 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19320/19320 [08:34<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mie文件数7659\n",
      "mie文件夹大小44.50 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_dir_size(path='.'):\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total\n",
    "\n",
    "datadir = r'/mnt/truenas_jiangxiaotian/Edataset/complexE/b7fd11d4af74b4ffddaa0161e9d3dfac'\n",
    "miedir = r'/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_Amphase/b7fd_E_mie_train'\n",
    "if not os.path.exists(miedir):\n",
    "        os.makedirs(miedir)\n",
    "print(f'文件数{len(os.listdir(datadir))}')\n",
    "print(f'文件夹大小{get_dir_size(datadir) / (1024 ** 3):.2f} GB')\n",
    "for filename in tqdm(os.listdir(datadir)):\n",
    "    # ([a-zA-Z0-9]{4})_theta(\\d+)(?:_)?phi(\\d+)(?:_)?f(\\d+\\.\\d+).pt\n",
    "    plane, theta, phi, f = re.match(r'([A-Za-z0-9]{4})_theta(\\d+)(?:_)?phi(\\d+)(?:_)?f(\\d+\\.\\d+).pt', filename).groups()\n",
    "    theta = int(theta); phi = int(phi); f = float(f)\n",
    "    if f >= 0.1 and f <= 1:\n",
    "        src = os.path.join(datadir, filename)\n",
    "        dst = os.path.join(miedir, filename)\n",
    "        shutil.copy(src, dst)\n",
    "print(f'mie文件数{len(os.listdir(miedir))}')\n",
    "print(f'mie文件夹大小{get_dir_size(miedir) / (1024 ** 3):.2f} GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源文件夹 (振幅相位): /mnt/truenas_jiangxiaotian/Edataset/complexE_mie_Amphase/b7fd_E_mie_AmPhase\n",
      "目标文件夹 (实部虚部): /mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_train\n",
      "检测到 7659 个文件，开始转换...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "转换进度: 100%|██████████| 7659/7659 [09:48<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "所有文件转换完成!\n",
      "转换后的文件已保存至: /mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_train\n",
      "转换后的文件数: 7659\n",
      "转换后的文件夹大小: 29.67 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def convert_amphase_to_realimage(amphase_dir, realimage_dir):\n",
    "    \"\"\"\n",
    "    将包含振幅相位信息的.pt文件转换为包含实部虚部信息的.pt文件。\n",
    "\n",
    "    输入张量维度: (360, 720, 6)\n",
    "    [Abs(E), Abs(Theta), Phase(Theta), Abs(Phi), Phase(Phi), Ax.Ratio]\n",
    "\n",
    "    输出张量维度: (360, 720, 4)\n",
    "    [Re(E_theta), Im(E_theta), Re(E_phi), Im(E_phi)]\n",
    "    \"\"\"\n",
    "    # 1. 创建目标文件夹\n",
    "    if not os.path.exists(realimage_dir):\n",
    "        os.makedirs(realimage_dir)\n",
    "    print(f\"源文件夹 (振幅相位): {amphase_dir}\")\n",
    "    print(f\"目标文件夹 (实部虚部): {realimage_dir}\")\n",
    "\n",
    "    # 2. 获取待处理的文件列表\n",
    "    try:\n",
    "        file_list = os.listdir(amphase_dir)\n",
    "        print(f\"检测到 {len(file_list)} 个文件，开始转换...\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：源文件夹不存在: {amphase_dir}\")\n",
    "        return\n",
    "\n",
    "    # 3. 循环处理每个文件\n",
    "    for filename in tqdm(file_list, desc=\"转换进度\"):\n",
    "        # 使用正则表达式确保只处理符合命名规则的文件\n",
    "        match = re.match(r'([A-Za-z0-9]{4})_theta(\\d+)(?:_)?phi(\\d+)(?:_)?f(\\d+\\.\\d+)\\.pt', filename)\n",
    "        if not match:\n",
    "            print(f\"\\n跳过不符合命名规则的文件: {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 构建完整的文件路径\n",
    "            src_path = os.path.join(amphase_dir, filename)\n",
    "\n",
    "            # 加载 PyTorch 张量\n",
    "            # 假设张量保存在CPU上\n",
    "            amphase_tensor = torch.load(src_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "            # 提取所需的振幅和相位通道\n",
    "            # 通道 1: Abs(Theta), 通道 2: Phase(Theta)\n",
    "            # 通道 3: Abs(Phi),   通道 4: Phase(Phi)\n",
    "            Etotal = amphase_tensor[:, :, 0]  # Abs(E)\n",
    "            amp_theta = amphase_tensor[:, :, 1]\n",
    "            phase_theta_deg = amphase_tensor[:, :, 2]\n",
    "            amp_phi = amphase_tensor[:, :, 3]\n",
    "            phase_phi_deg = amphase_tensor[:, :, 4]\n",
    "\n",
    "            # 将相位从度(degree)转换为弧度(radian)\n",
    "            # 使用 torch.pi 以保证精度和计算效率\n",
    "            phase_theta_rad = phase_theta_deg * (torch.pi / 180.0)\n",
    "            phase_phi_rad = phase_phi_deg * (torch.pi / 180.0)\n",
    "\n",
    "            # 核心转换：根据欧拉公式计算实部和虚部\n",
    "            # Real = Amplitude * cos(Phase_rad)\n",
    "            # Imag = Amplitude * sin(Phase_rad)\n",
    "            re_theta = amp_theta * torch.cos(phase_theta_rad)\n",
    "            im_theta = amp_theta * torch.sin(phase_theta_rad)\n",
    "            re_phi = amp_phi * torch.cos(phase_phi_rad)\n",
    "            im_phi = amp_phi * torch.sin(phase_phi_rad)\n",
    "\n",
    "            # 将四个部分堆叠成一个新的  张量\n",
    "            # realimage_tensor = torch.stack([Etotal, re_theta, im_theta, re_phi, im_phi], dim=-1) # (360, 720, 5),第0维为 Etotal\n",
    "            realimage_tensor = torch.stack([re_theta, im_theta, re_phi, im_phi], dim=-1) # (360, 720, 4)\n",
    "\n",
    "            # 构建新的文件名（在.pt前加上_RI）\n",
    "            base_name, ext = os.path.splitext(filename)\n",
    "            new_filename = f\"{base_name}_RI{ext}\"\n",
    "            dst_path = os.path.join(realimage_dir, new_filename)\n",
    "\n",
    "            # 保存转换后的新张量\n",
    "            torch.save(realimage_tensor, dst_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n处理文件 {filename} 时发生错误: {e}\")\n",
    "\n",
    "    print(\"\\n所有文件转换完成!\")\n",
    "    print(f\"转换后的文件已保存至: {realimage_dir}\")\n",
    "    print(f\"转换后的文件数: {len(os.listdir(realimage_dir))}\")\n",
    "    print(f\"转换后的文件夹大小: {get_dir_size(realimage_dir) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "amphase_source_dir = r'/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_Amphase/b7fd_E_mie_train'\n",
    "realimage_target_dir = r'/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_train'\n",
    "convert_amphase_to_realimage(amphase_source_dir, realimage_target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f545a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage\n",
      "b7fd_E_mie_train\n",
      "b7fd_E_mie_val\n",
      "/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_val\n"
     ]
    }
   ],
   "source": [
    "traindir = r'/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_train'\n",
    "print(os.path.dirname(traindir))\n",
    "print(os.path.basename(traindir))\n",
    "print(os.path.basename(traindir).replace('_train','_val'))\n",
    "print(os.path.join(os.path.dirname(traindir), os.path.basename(traindir).replace('_train','_val')))\n",
    "# valdir = os.path.dirname(traindir) + os.path.basename(traindir).replace('_train','_val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29466974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原训练集地址/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_train\n",
      "原训练集文件数7659\n",
      "原训练集文件夹大小29.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 765/7659 [00:02<00:21, 313.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集地址/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_val\n",
      "原总集文件数6894\n",
      "验证集文件数765\n",
      "验证集文件夹大小2.96 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 689/6894 [00:31<04:45, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集地址/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_10train\n",
      "0.1训练集文件数689\n",
      "0.1训练集文件夹大小2.67 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3447/6894 [03:01<03:01, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集地址/mnt/truenas_jiangxiaotian/Edataset/complexE_mie_RealImage/b7fd_E_mie_50train\n",
      "0.5训练集文件数3447\n",
      "0.5训练集文件夹大小13.35 GB\n"
     ]
    }
   ],
   "source": [
    "traindir = realimage_target_dir\n",
    "print(f'原训练集地址{traindir}')\n",
    "print(f'原训练集文件数{len(os.listdir(traindir))}')\n",
    "print(f'原训练集文件夹大小{get_dir_size(traindir) / (1024 ** 3):.2f} GB')\n",
    "\n",
    "valdir = os.path.join(os.path.dirname(traindir), os.path.basename(traindir).replace('_train','_val'))\n",
    "train10dir = os.path.join(os.path.dirname(traindir), os.path.basename(traindir).replace('_train','_10train'))\n",
    "train50dir = os.path.join(os.path.dirname(traindir), os.path.basename(traindir).replace('_train','_50train'))\n",
    "\n",
    "def split_val(src_dir, val_dir, val_ratio=0.1):\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "\n",
    "    files = os.listdir(src_dir)\n",
    "    total_files = len(files)\n",
    "    val_size = int(total_files * val_ratio)\n",
    "\n",
    "    for i, filename in enumerate(tqdm(files)):\n",
    "        src_file = os.path.join(src_dir, filename)\n",
    "        if i < val_size:\n",
    "            dst_file = os.path.join(val_dir, filename)\n",
    "            shutil.move(src_file, dst_file)\n",
    "        else:\n",
    "            break\n",
    "    print(f'验证集地址{val_dir}')\n",
    "    print(f'原总集文件数{len(os.listdir(src_dir))}')\n",
    "    print(f'验证集文件数{len(os.listdir(val_dir))}')\n",
    "    print(f'验证集文件夹大小{get_dir_size(val_dir) / (1024 ** 3):.2f} GB')\n",
    "    \n",
    "def split_train(src_dir, train_dir, train_ratio=0.1):\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "\n",
    "    files = os.listdir(src_dir)\n",
    "    total_files = len(files)\n",
    "    train_size = int(total_files * train_ratio)\n",
    "\n",
    "    for i, filename in enumerate(tqdm(files)):\n",
    "        src_file = os.path.join(src_dir, filename)\n",
    "        if i < train_size:\n",
    "            dst_file = os.path.join(train_dir, filename)\n",
    "            shutil.copy(src_file, dst_file)\n",
    "        else:\n",
    "            break\n",
    "    print(f'训练集地址{train_dir}')\n",
    "    print(f'{train_ratio}训练集文件数{len(os.listdir(train_dir))}')\n",
    "    print(f'{train_ratio}训练集文件夹大小{get_dir_size(train_dir) / (1024 ** 3):.2f} GB')\n",
    "\n",
    "# Split validation set\n",
    "split_val(traindir, valdir, val_ratio=0.1)\n",
    "# Split training set into 10% and 50%\n",
    "split_train(traindir, train10dir, train_ratio=0.1)\n",
    "split_train(traindir, train50dir, train_ratio=0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jxtnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
